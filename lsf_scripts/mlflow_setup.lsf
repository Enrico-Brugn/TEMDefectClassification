#!/bin/bash

#BSUB -J "ae_texture_dev"
#BSUB -q dev
#BSUB -n 1
#BSUB -R "rusage[ngpus_excl_p=1] span[hosts=1]"
#BSUB -e "../results/derr/%J.stderr"
#BSUB -o "../results/dout/%J.stdout"

module purge 
module load Anaconda3/2019.03-rhel-7
source activate temdef_env

cd ../scripts


export MLFLOW_TRACKING_URI=http://mlflow2.temdefvm1.zc2.ibm.com:5000
export MLFLOW_S3_ENDPOINT_URL=http://mlflow2.temdefvm1.zc2.ibm.com:9000
export AWS_ACCESS_KEY_ID=access-key
export AWS_SECRET_ACCESS_KEY=secret-key
export MLFLOW_EXPERIMENT_NAME=enn_gputrying3

mlflow experiments create --artifact-location s3://mlflow -n ${MLFLOW_EXPERIMENT_NAME}

#Parsing Parameters
#AUGMENTATION=$"0"
#TEST=$"False"
#MODEL=$"0"
#TOPOLOGY=$"contracting"
#LOSS=$"mse_spectral"
#EPOCHS=$"5"
#STEPS=$"8"
#BATCH_SIZE=$"25"
#LEARNING_RATE=$"0.00001"
#BETA=$"100"
#KSIZE=$"10"

python3 run.py -l 'mse_spectral' -e 124

#mlflow run . --no-conda -P batchsize=20 #augmentation=$AUGMENTATION  -P test=$TEST  -P model=$MODEL  -P topology=$TOPOLOGY  -P loss=$LOSS  -P epochs=$EPOCHS  -P steps=$STEPS  -P batch_size=$BATCH_SIZE  -P learning_rate=$LEARNING_RATE  -P beta=$BETA  -P ksize=$KSIZE

: << ////
python3 run.py -l 'mse_spectral' -e 80 -s 32 -b 16 -lr 0.0001
python3 run.py -l 'mse_spectral' -e 150 -s 32 -b 16 -lr 0.0001
python3 run.py -l 'mse_spectral' -e 300 -s 32 -b 16 -lr 0.0001
python3 run.py -l 'mse_spectral' -e 500 -s 32 -b 16 -lr 0.0001
////
